<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta
      name="description"
      content="A collection of pledges made by the people at People and Code"
    />
    <link rel="stylesheet" href="/src/styles/common.css" />
    <title>Pledge to think before using AI</title>
    <link rel="icon" type="image/x-icon" href="/src/media/favicon.ico" />
  </head>
  <body class="body">
    <header>
      <h1>Think before using AI</h1>
    </header>
    <main class="main">
      <article>
        <section aria-labelledby="the-pledge">
          <h2 id="the-pledge">The pledge</h2>
          <p class="pledge">
            <em>
              I pledge to put down my ideas on paper before asking for help from
              Claude or ChatGPT,
              <time datetime="PT14">for the next two weeks</time>,
              <span
                >in order that I will produce better work in the same amount of
                time.</span
              >
            </em>
          </p>
        </section>
        <section aria-labelledby="intention">
          <h3 id="intention">Intention</h3>
          <p>
            Why did I make this pledge? I use
            <a href="https://claude.ai/">Claude</a> and
            <a href="https://chat.openai.com/">ChatGPT</a> a lot. I know they
            consume energy, create emissions, and use water both during their
            training phase and when they are running.
          </p>
          <p>
            The numbers for these operations (our calculations) are probably of
            the correct magnitude but their significance is not clear to me.
            Comparing the training of an LLM to X number of flights doesn't tell
            me whether the training should have gone ahead, or whether I should
            use the model. Should the flights have flown? Were they for a good
            reason? What is a lot of flights?
          </p>
          <p>
            Even if I knew the answer to these questions, I don't think it would
            matter. If LLMs are useful - and they are - we are going to use
            them. If the
            <a href="https://en.wikipedia.org/wiki/Jevons_paradox"
              >Jevons paradox</a
            >
            applies, we will use LLMs - or generative AI - to do more, whether
            that more is valuable or not.
          </p>
        </section>
        <section aria-labelledby="hypothesis">
          <h3 id="hypothesis">Hypothesis</h3>
          <p>
            Therefore, I am looking at this the other way around. Rather than
            monitor my LLM usage, I will keep a watchful eye on my intentions.
            The idea is to know my goal in advance and use LLMs to achieve the
            task in less time, or to do it better. Ideally both things would be
            true.
          </p>
          <p>
            I am assuming that by doing things quicker or better, I will save
            energy (and by association emissions, water, etc.).
          </p>
        </section>
        <section aria-labelledby="outcome">
          <h3 id="outcome">Outcome</h3>
          <p>I don't know how to measure the outcome of this pledge.</p>
          <p>
            I will therefore measure success by whether or not I do write things
            down. I can verify that. In addition, I <em>aspire</em> to work
            faster and better. This approach is unscientific but still, I think
            valid, because the pledge is really about my - human - behaviour,
            not whether or not AI can help me.
          </p>
          <p>
            The outcome section was written after I asked Claude what it
            thought. I didn't change anything. Here is part of its reply:
          </p>
          <blockquote>
            <p>
              This reminds me of other situations where the act of preparation
              or reflection itself can be more valuable than any measurable
              outcome. For instance, the practice of writing a project brief
              often clarifies thinking regardless of whether the final product
              strictly follows that brief.
            </p>
            <cite>Claude</cite>
          </blockquote>
        </section>
        <small>
          <p>
            <em>
              <time datetime="2024-11-06">Wed 06 Nov 2024</time>
            </em>
          </p>
          <p class="pledger"><em>pledger: Dan</em></p>
        </small>
        <section aria-labelledby="update">
          <h4 id="update">Update</h4>
          <p>
            I stuck to my pledge and committed more ideas to paper. I also began
            to sketch out the idea of using AI as a ratchet for iterating on
            ideas.
          </p>
          <p>
            I completed one project without recourse to AI: a client/server
            environment to accompany a workshop on HTTP messaging.
          </p>
        </section>
        <section aria-labelledby="further-reading">
          <h2 id="further-reading">Further reading</h2>
          <ul>
            <li>
              <a
                href="https://responsibletech.work/tools/development/pledge-works/"
                >Pledge Works</a
              >
            </li>
          </ul>
        </section>
      </article>
    </main>
    <footer>
      <nav aria-label="Primary">
        <a href="/src/sitemap.html">Contents</a>
      </nav>
    </footer>
  </body>
</html>
