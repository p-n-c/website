<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta
      name="description"
      content="How to navigate an interaction with an LLM without getting lost"
    />
    <link rel="stylesheet" href="/src/styles/common.css" />
    <title>Escaping the labyrinth</title>
    <link rel="icon" type="image/x-icon" href="/src/media/favicon.ico" />
  </head>
  <body class="body">
    <header>
      <a href="#main" class="skip">Skip to main content</a>
      <div>
        <h1>Escaping the labyrinth</h1>
      </div>
    </header>
    <main id="main" class="main">
      <div class="byline">
        <img
          class="byline-logo"
          src="/src/media/pac-logo.svg"
          alt="People and code logo."
        />
        <div>
          <div class="byline-brand">People and Code</div>
          <div class="byline-tagline">At Your Disposal</div>
        </div>
      </div>
      <p>
        My prompts to LLMs for input sometimes lead to a stream of code and
        explanatory notes that I don't want. It's tempting to try and fix things
        in media res but I usually start over. This affects me in a couple of
        ways: I feel bad that I've wasted resources through my carelessness; the
        mess I've created takes the edge off my enthusiasm.
      </p>
      <p>
        This typically happens when I'm working on a small project; something
        that might require a few files, and a handful of functions. And disaster
        can strike at any moment. I ask for tests but forget to mention that I'm
        using vitest now and not jest, or I fail to stipulate that I want to be
        asked before adding dependencies. Myriad unread lines spool down the
        screen.
      </p>
      <p>Then I remembered the ball of thread Ariadne gave to Theseus.</p>
      <aside>
        <h2 id="ariadnes-thread">Ariadne's Thread</h2>
        <p>
          In Greek mythology, the Cretan princess, Ariadne handed Theseus a ball
          of thread before he entered the labyrinth at Knossos so that that he
          might find his way back to safety after confronting, and killing, the
          Minotaur.
        </p>
      </aside>
      <section aria-labelledby="the-thread">
        <h3 id="the-thread">The thread</h3>
        <p>
          <em
            ><strong>Thread</strong>: The record of an interaction between a
            developer and an LLM. Contains the thread prompt used to initialise
            the interaction and a collection of snapshots.</em
          >
        </p>
        <p>
          I will use a <strong>thread</strong> to encapsulate the interactions I
          have with LLMs.
        </p>
        <p>
          My thread is a simply structured record written in JSON. Here's the
          first part of it:
        </p>
        <aside>
          <section aria-labelledby="the-json-thread">
            <h2 id="the-json-thread"><em>thread.json</em></h2>
            <pre id="json-thread" class="json">
              {        
                thread: {
                  threadPrompt: {
                    project: {
                      title: 'project title',
                      description: 'project description',
                      definition: 'project definition',
                    },
                    prototype: {
                      type: 'prototype',
                      definition: 'prototype definition',
                    },
                  },
                },
              }
            </pre>
          </section>
        </aside>
        <section aria-labelledby="the-project">
          <h4 id="the-project">The project</h4>
          <p>
            We start with some information about the project, the sort of things
            you'd expect to find in any prompt: title, description and
            definition. A title helps when discussing the project. The
            definition will depend on what kind of project it is. At this stage,
            it's a prototype and I pick from one of five types: conceptual,
            vertical, horizontal, functional and visual. (Here is a longer list
            of
            <a
              href="https://github.com/p-n-c/ariadnes-thread/blob/main/ariadnes-thread/prototype-types.json"
              >prototype types</a
            >).
          </p>
          <p>
            The project and prototype details go in the
            <strong>thread prompt</strong>. It will govern the entire
            interaction related to the project. In nature, it sits somewhere
            between a one off prompt and a systems prompt.
          </p>
          <p>
            <em
              ><strong>Thread prompt</strong>: Used to initialise a thread.
              Contains project-specific details, rules on how an LLM should
              interact and how it should format periodic summaries
              (snapshots).</em
            >
          </p>
        </section>
        <section aria-labelledby="interaction-guidelines">
          <h4 id="interaction-guidelines">Interaction guidelines</h4>

          <p>
            The next thing I add to the thread prompt are the
            <strong>interaction guidelines</strong>; ground rules or guidelines
            for the LLM to follow during the interaction. I include an explicit
            direction: "The LLM should follow these guidelines throughout" so
            that their purpose is clear.
          </p>
          <p>
            <strong>Rules</strong> govern things like whether the LLM should
            show code by default. Two are particularly effective for pacing the
            LLM's response:
          </p>
          <ul>
            <li><code>confirmBeforeAdvancing</code></li>
            <li><code>explainOneConceptAtATime</code></li>
          </ul>
          <p>
            They cause the LLM to break solutions down into steps and iterate
            over them.
          </p>
          <p>
            Here's my updated thread. The thread prompt has been fleshed out to
            include our rules, terms and I've add a new, top-level, field,
            <strong>snapshots</strong>:
          </p>
        </section>
        <aside>
          <section aria-labelledby="the-json-thread-2">
            <h2 id="the-json-thread-2">
              <em>thread.json</em> (now with rules, terms and snapshots)
            </h2>
            <pre id="json-thread-2" class="json">
              {
                thread: {
                  threadPrompt: {
                    project: {
                      title: 'project title',
                      description: 'project description',
                      definition: 'project definition',
                    },
                    prototype: {
                      type: 'prototype',
                      definition: 'prototype definition',
                    },
                    interactionGuidelines: {
                      description: 'The LLM should follow these guidelines throughout.',
                      rules: {
                        conciseByDefault: true,
                        showCodeByDefault: false,
                      },
                      terms: {
                        threadPrompt: {
                          definition: 'Used to initialise a thread. Containsâ€¦',
                        },
                      },
                    },
                  },
                  snapshots: [],
                },
              }
            </pre>
            <p>
              Here's a
              <a
                href="https://github.com/p-n-c/project-prototype-generator/blob/main/lib/projects/basic/templates/artefacts/thread.json"
                >complete thread</a
              >
              with a full set of rules and terms.
            </p>
          </section>
        </aside>
      </section>
      <section aria-labelledby="the-snapshot">
        <h3 id="the-snapshot">The snapshot</h3>
        <p>
          <em
            ><strong>Snapshot</strong>: A specific interaction state
            representative of progress to date. A snapshot should conform to the
            snapshot schema.</em
          >
        </p>
        <p>The snapshot is how I keep track of what's going on.</p>
        <p>
          Whenever I want a summary of the interaction to date, need to slow
          things down, or want to record where I am before changing direction, I
          ask the LLM for a snapshot.
        </p>
        <p>
          I keep a record of snapshots by copying and pasting them into the
          snapshots array in my thread.
        </p>
        <p>
          The <strong>snapshot schema</strong> describes what these summaries
          should look like. I've written it in JSON because I find it easy to
          parse but it could be in YAML or Markdown (it makes no difference to
          the LLM).
        </p>
        <aside>
          <section aria-labelledby="json-snapshot-schema">
            <h5 id="json-snapshot-schema">The snapshot schema</h5>
            <pre id="json-snapshot" class="json">
                {
                  schema: {
                    project: {
                      title: 'string',
                      description: 'string',
                      definition: 'string',
                    },
                    prototype: {
                      type: 'string',
                      definition: 'string',
                    },
                    summary: 'string',
                  },
                }
              </pre
            >
          </section>
        </aside>
      </section>
      <p>
        You'll notice the snapshot has a copy of the project and prototype
        objects. This reminds the developer and the LLM of the purpose of the
        chat as well as making the snapshot portable.
      </p>
      <section aria-labelledby="artefacts">
        <h3 id="artefacts">Artefacts</h3>
        <p>
          I now have a thread which contains details of my project, interaction
          guidelines, and a snapshots array for tracking progress. Where should
          I put it?
        </p>
        <p>
          It makes sense to keep the thread in the project itself but separate
          from the source code. I prefer to put the thread in a dedicated
          folder,
          <strong>artefacts</strong>, which is where I'll also add files I add
          to the interaction (e.g. examples of expected outputs) as well as code
          or designs generated by the LLM.
        </p>
        <p>
          That's it. The thread initialises my interaction with the LLM. I flip
          between the chat and the project using the files in artefacts as a
          buffer. Working there, away from the distractions and temptations of
          the chat interface, I am self-reliant.
        </p>
        <aside>
          <section aria-labelledby="the-artefacts-folder">
            <h4 id="the-artefacts-folder">The artefacts folder</h4>
            <pre class="json">
                artefacts: 
                  thread.json
                  // uploaded files and examples
                  // responses provided by the LLM
                src: 
                  // project code
              </pre
            >
          </section>
        </aside>
      </section>
      <section aria-labelledby="workflow">
        <h3 id="workflow">Workflow</h3>
        <p>
          How does Ariadne's Thread work in practice? Here's a step-by-step
          guide to creating a thread for a small project:
        </p>
        <ul>
          <li>Create your project (I use VS Code)</li>
          <li>Add an artefacts folder</li>
          <li>
            Create a new thread prompt in artefacts with project details,
            interaction rules and how you want the LLM to write snapshots
          </li>
          <li>Open a new chat and upload the thread</li>
          <li>
            Add any files used during the interaction to artefacts, including
            those generated by the LLM
          </li>
          <li>
            When you need a summary of progress to date, ask for a snapshot and
            add it to the snapshots array
          </li>
          <li>
            Use the snapshots and LLM responses inside artefacts to think over
            what you are doing before working on source code away from the
            distractions of a chat interface
          </li>
        </ul>
        <aside>
          <p>
            The Ariadne's Thread repo has a visual representation of the
            <a
              href="https://github.com/p-n-c/ariadnes-thread/blob/main/WORKFLOW.md"
              >workflow</a
            >.
          </p>
        </aside>
        <section aria-labelledby="example">
          <h4 id="example">
            Example - Building a simple RSS feed generator with Claude
          </h4>
          <p>
            I used Ariadne's Thread to create a simple RSS feed generator. In
            the
            <a
              href="https://github.com/p-n-c/rss-feed-generator/tree/main/artefacts"
              >artefacts</a
            >
            folder you will find a thread, an example of an RSS feed which I
            added to the chat, and an rss-generator file with code from the LLM.
            Because I had asked Claude to proceed incrementally, it returned
            small chunks of code (numbered 1-4) which I evaluated and refactored
            before using in the source code.
          </p>
        </section>
      </section>
      <section aria-labelledby="conclusion">
        <h2 id="conclusion">Conclusion</h2>
        <p>
          In order not to get lost in the maze of dead-ends and wrong turns
          caused by muddled thinking, I struck on the metaphor of the thread
          which Ariadne gave to Theseus to help him navigate the labyrinth.
        </p>
        <p>
          Creating a thread has the effect of making me think more carefully
          before starting a new project. Its structure and documentation afford
          me better oversight and - if I ask an LLM to assist me - the means to
          moderate our interaction.
        </p>
        <aside>
          <p>
            The
            <a href="https://github.com/p-n-c/project-prototype-generator"
              >project prototype generator</a
            >
            expedites creating a prototype that supports Ariadne's Thread. When
            you create a new prototype, the artefacts folder and a thread
            complete with thread prompt is included. A list of human prompts
            will help you define your project.
          </p>
        </aside>
      </section>
      <hr />
      <p>Author: <em>Daniel Hartley</em></p>
      <p>
        <em>This article was published on 6th March 2025.</em>
      </p>
      <hr />
      <section aria-labelledby="thread-history-schema">
        <h2 id="thread-history-schema">Terms</h2>
        <dl>
          <dt><strong>Thread</strong></dt>
          <dd>
            The record of an interaction between a developer and an LLM.
            Contains the thread prompt used to initialise the interaction and a
            collection of snapshots.
          </dd>
          <dt><strong>Thread prompt</strong></dt>
          <dd>
            Used to initialise a thread. Contains project-specific details,
            rules on how an LLM should interact and how it should format
            periodic summaries (snapshots).
          </dd>
          <dt><strong>Snapshot</strong></dt>
          <dd>
            A specific interaction state representative of progress to date. A
            snapshot should conform to the snapshot schema.
          </dd>
        </dl>
      </section>
      <hr />
      <section aria-labelledby="reference">
        <h2 id="reference">Reference</h2>
        <ul>
          <li><a href="https://en.wikipedia.org/wiki/Ariadne">Ariadne</a></li>
          <li>
            <a href="https://github.com/p-n-c/ariadnes-thread/tree/main"
              >Ariadne's Thread</a
            >
          </li>
          <li>
            <a
              href="https://github.com/p-n-c/ariadnes-thread/blob/main/ariadnes-thread/prototype-types.json"
              >Prototype types</a
            >
          </li>
          <li>
            <a
              href="https://www.researchgate.net/publication/385743952_The_Risks_Of_Human_Overreliance_On_Large_Language_Models_For_Critical_Thinking"
              >The Risks Of Human Overreliance On Large Language Models For
              Critical Thinking by Duenas and Ruiz</a
            >
          </li>
          <li>
            <a href="https://arxiv.org/abs/2410.03703"
              >Human Creativity in the Age of LLMs by Kumar et al.</a
            >
          </li>
          <li>
            <a href="https://journals.sagepub.com/doi/10.1177/02734753241305980"
              >Generative AIâ€™s Impact on Critical Thinking: Revisiting Bloomâ€™s
              Taxonomy by Chahna Gonsalves</a
            >
          </li>
          <li>
            <a
              href="https://steve-yegge.medium.com/the-death-of-the-stubborn-developer-b5e8f78d326b"
              >The Death of the Stubborn Developer by Steve Yegge</a
            >
          </li>
        </ul>
      </section>
      <section aria-labelledby="potential-improvements">
        <h2 id="potential-improvements">Potential improvements</h2>
        <p>
          I asked Claude to suggest potential improvements. It touched on many
          of the ideas we have discussed at People and Code, and that my
          colleague, JP, has raised.
        </p>
        <blockquote>
          <p>
            Looking at potential improvements for the Ariadne's Thread approach,
            I see several opportunities to enhance its effectiveness:
          </p>
          <ul>
            <li>
              Version Control Integration - The current implementation relies on
              manually copying snapshots into the thread. Integrating with Git
              or another version control system could automate this process,
              creating commits at each snapshot and maintaining a more reliable
              history.
            </li>
            <li>
              Structured Feedback Loop - Adding a dedicated section in the
              thread for tracking which LLM suggestions worked well and which
              didn't could improve future interactions. This "lessons learned"
              component would help refine prompts over time.
            </li>
            <li>
              Collaborative Extensions - The approach seems optimized for solo
              developers. Adding support for team-based workflows, perhaps with
              role-specific guidelines for different team members, would make it
              more versatile for larger projects.
            </li>
            <li>
              Templating System - While the article mentions a prototype
              generator, a more robust templating system for different project
              types (web app, CLI tool, data pipeline, etc.) would save time and
              standardize interactions across similar projects.
            </li>
            <li>
              Visualization Tools - A simple UI to visualize the thread's
              progression could help identify patterns in the development
              process, showing where the most iterations occurred or where
              progress stalled.
            </li>
            <li>
              Metrics and Analytics - Adding quantitative measures like time
              spent per development phase or the ratio of LLM-generated code
              that makes it to production could provide insights for process
              improvement.
            </li>
            <li>
              Cross-LLM Compatibility - The approach could be extended to work
              seamlessly across different LLMs, possibly with adapter patterns
              to normalize the interaction patterns between different AI
              systems.
            </li>
            <li>
              Context Window Management - As projects grow, they can exceed the
              context window of many LLMs. A mechanism to intelligently
              summarize or partition the thread while maintaining critical
              context would be valuable.
            </li>
            <li>
              Privacy Controls - For sensitive projects, a filtering mechanism
              to control what information is shared with the LLM would enhance
              security.
            </li>
            <li>
              Machine-Readable Output Format - While JSON is a good start, a
              more strictly defined schema would enable programmatic processing
              of threads, potentially allowing for automated analysis or
              integration with other development tools.
            </li>
          </ul>
          <p><em>Claude 3.7 Sonnet</em></p>
        </blockquote>
      </section>
    </main>
    <footer id="footer">
      <nav aria-label="Primary">
        <a href="/src/index.html">Home</a>
        <a href="/src/people.html">People</a>
        <a href="/src/code.html">Code</a>
        <a href="/src/writing.html">Writing</a>
        <a href="https://workshops.people-and-code.com">Workshops</a>
      </nav>
      <div class="copyright">
        &copy; 2025 People and Code. All rights reserved.
      </div>
    </footer>
  </body>
  <script>
    {
      const json = {
        thread: {
          threadPrompt: {
            project: {
              title: 'project title',
              description: 'project description',
              definition: 'project definition',
            },
            prototype: {
              type: 'prototype',
              definition: 'prototype definition',
            },
          },
        },
      }
      document.getElementById('json-thread').innerHTML = JSON.stringify(
        json,
        undefined,
        2
      )
      const json2 = {
        thread: {
          threadPrompt: {
            project: {
              title: 'project title',
              description: 'project description',
              definition: 'project definition',
            },
            prototype: {
              type: 'prototype',
              definition: 'prototype definition',
            },
            interactionGuidelines: {
              description: 'The LLM should follow these guidelines throughout.',
              rules: {
                conciseByDefault: true,
                showCodeByDefault: false,
              },
              terms: {
                threadPrompt: {
                  definition: 'Used to initialise a thread. Containsâ€¦',
                },
              },
            },
          },
          snapshots: [],
        },
      }
      document.getElementById('json-thread-2').innerHTML = JSON.stringify(
        json2,
        undefined,
        2
      )
      const jsonSnapshot = {
        schema: {
          project: {
            title: 'string',
            description: 'string',
            definition: 'string',
          },
          prototype: {
            type: 'string',
            definition: 'string',
          },
          summary: 'string',
        },
      }
      document.getElementById('json-snapshot').innerHTML = JSON.stringify(
        jsonSnapshot,
        undefined,
        2
      )
    }
  </script>
</html>
